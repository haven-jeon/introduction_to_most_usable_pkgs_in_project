geom_point()  +
geom_smooth()
dev.off()
?ggsave
ymd(20121223)
Sys.getlocale()
Sys.setlocale(LC_TIME="C")
Sys.setlocale("LC_TIME", "C")
ymd(20121223)
getwd()
getwd("../")
setwd("../")
getwd()
knit("bicdata.Rmd", encoding="UTF-8")
knit("bicdata.Rmd", encoding="UTF-8")
system("pandoc -o bicdata.docx bicdata.md")
options("encoding")
options("rpubs.upload.method")
options(rpubs.upload.method="internal")
Sys.setlocale("LC_TIME", "C")
install.packages(c("colorspace", "dichromat", "shiny"))
library(markdown)
system("pandoc -o bicdata.docx bicdata.md")
install.packages(c("digest", "markdown", "rgl", "stargazer"))
library(shiny)
runExample("02_text")
runExample("03_reactivity")
library(ProjectTemplate)
load.project()
install.packages(c("nlme", "slam"))
install.packages("mgcv")
library(ProjectTemplate)
create.project("gogamza")
getwd()
setwd("gogamza")
getwd()
system("dir/w")
system("ls -al")
titanic <- read.csv("http://dl.dropbox.com/u/8686172/titanic.csv")
head(titanic)
write.csv(titanic, file = "data/titanic.csv")
load.project()
rm(list=ls())
load.project()
View(titanic)
head(titanic)
summary(titanic)
rm(list=ls())
load.project()
View(titanic)
stub.tests()
helper.function()
test.project()
test.project
?test_dir
test.project
test.project()
test.project()
load("G:/nstep_macro_detection/data/recs.RData")
recs
nrow(recs)
library(RWordPress)
library(devtools); install_github('knitr', 'yihui')
library(knitr)
options(WordpressLogin = c(admin = 'KoNLP13675!'),
WordpressURL = 'http://freesearch.pe.kr/xmlrpc.php')
knit2wp('bicdata.Rmd', title = '워드프레스 테스트',)
?knit2wp
knit2wp
?knit2html
getOption("encoding")
native_encoding <- getOption("encoding")
native_encoding <- getOption("encoding")
options(encoding="UTF-8")
knit2wp('bicdata.Rmd', title = '워드프레스 테스트')
options(encoding=native_encoding)
getOption("encoding")
?knit2wp
getwd()
knit2wp
library(igraph)
?authority.score
library(tm.plugin.webmining)
install.packages("tm.plugin.webmining")
library(tm.plugin.webmining)
options("java.parameters")
library(tm.plugin.webmining)
options("jva.parameters")
options("java.parameters")
help(package="tm.plugin.webmining")
library(XML)
library(RCurl)
xml.url <- "http://live.reuters.com/Event/rss.aspx?id=70335"
script  <- getURL(xml.url)
doc     <- xmlParse(script)
titles    <- xpathSApply(doc,'//item/title',xmlValue)
pubdates <- xpathSApply(doc,'//item/pubDate',xmlValue)
reuters<-cbind(titles, pubdates)
reuters_data<-data.frame(reuters)
#Exporting as a csv
head(reuters_data)
xml.url <- "http://news.mk.co.kr/rss/all.xml"
script  <- getURL(xml.url)
doc     <- xmlParse(script)
titles    <- xpathSApply(doc,'//item/title',xmlValue)
pubdates <- xpathSApply(doc,'//item/pubDate',xmlValue)
reuters<-cbind(titles, pubdates)
reuters_data<-data.frame(reuters)
head(reuters_data)
?xmlParse
script
?getURL
script  <- getURL(xml.url, .encoding = "UTF-8")
script
Sys.getlocale(category = "LC_CTYPE")
class(script)
Encoding(script) <- "UTF-8"
script
basicTextGatherer
?basicTextGatherer
?getURL
script  <- getURL(xml.url, .encoding = "cp949")
head(script)
doc     <- xmlParse(script)
doc
titles    <- xpathSApply(doc,'//item/title',xmlValue)
pubdates <- xpathSApply(doc,'//item/pubDate',xmlValue)
reuters<-cbind(titles, pubdates)
reuters_data<-data.frame(reuters)
head(reuters_data)
head(doc)
doc     <- xmlParse(script)
doc
?xpathSApply
class(rss)
class(doc)
?xmlParse
class(script)
script <- enc2utf8(script)
script
doc     <- xmlParse(script)
Encoding(script)
doc     <- xmlParse(script,encoding="UTF-8")
doc
script  <- getURL(xml.url, .encoding = "cp949")
script <- enc2utf8(script)
script  <- getURL(xml.url, .encoding = "cp949")
doc     <- xmlParse(script,encoding="cp949")
doc
titles    <- xpathSApply(doc,'//item/title',xmlValue)
title
titles
?xpathSApply
titles    <- xpathSApply(doc,'//item/title',xmlValue,encoding="cp949")
titles
?xpathSApply
xmlValue
titles    <- xpathSApply(doc,'//item/title',xmlValue, encoding="cp949")
titles
titles    <- xpathSApply(doc,'//item/title',xmlValue, sessionEncoding="cp949")
titles
xmlValue
getEncoding(doc)
getEncoding
script  <- getURL(xml.url, .encoding = "euc-kr")
xml.url <- "http://news.mk.co.kr/rss/all.xml"
script  <- getURL(xml.url, .encoding = "euc-kr")
doc     <- xmlParse(script,encoding="euc-kr")
titles    <- xpathSApply(doc,'//item/title',xmlValue)
titles
Encoding(title)
Encoding(titles[1])
library(RJSONIO)
list <- fromJSON(script)
script
?RJSONIO
help(package="RJSONIO")
script
getEncoding
getEncoding(script)
doc     <- xmlParse(script,encoding="euc-kr")
doc
class(doc)
?xpathSApply
r <- xmlRoot(doc)
r
?xmlRoot
?getURL
script  <- getURL(xml.url, .encoding = "UTF-8")
script
Encoding(script) <- "UTF-8"
script
?getURL
options("encoding")
getOption("encoding")
nativ <- getOption("encoding")
options(encoding="UTF-8")
script  <- getURL(xml.url, .encoding = "UTF-8")
script
Sys.getlocale(category = "LC_CTYPE")
options(encoding=nativ)
Sys.setlocale("LC_CTYPE","korean")
script  <- getURL(xml.url, .encoding = "UTF-8")
script
script  <- getURL(xml.url, .encoding = "euc-kr")
script
doc     <- xmlParse(script,encoding="euc-kr")
doc
titles    <- xpathSApply(doc,'//item/title',xmlValue)
titles
fix(titles)
doc
class(doc)
?xmlValue
xpathSApply
script  <- getURL(xml.url, .encoding = "euc-kr")
#Encoding(script) <- "UTF-8"
#script <- enc2utf8(script)
doc     <- xmlParse(script,encoding="euc-kr")
#r <- xmlRoot(doc)
doc
class(script)
titles    <- xpathSApply(doc,'/item/title',xmlValue)
titles
xmlValue
XML::xmlValue
titles    <- xpathSApply(doc,'//item/title',xmlValue, encoding="euc-kr")
titles
titles[1]
titles    <- xpathSApply(doc,'//item/title',xmlValue, encoding="utf-8")
titles[2]
titles[1]
Encoding(titles[1])
titles    <- xpathSApply(doc,'//item/title',xmlValue, encoding="utf-8")
pubdates <- xpathSApply(doc,'//item/pubDate',xmlValue,encoding="utf-8")
reuters<-cbind(titles, pubdates)
reuters
doc
description <- xpathSApply(doc,'//item/description',xmlValue,encoding="utf-8")
mknews<-cbind(titles, description)
mknews_df<-data.frame(mknews)
mknews_df
getEncoding(doc)
xml.url <- "http://rss.ohmynews.com/rss/ohmynews.xml"
script  <- getURL(xml.url, .encoding = "euc-kr")
script
xml.url <- "http://rss.ohmynews.com/rss/ohmynews.xml"
script  <- getURL(xml.url, .encoding = "euc-kr")
script  <- getURL(xml.url, .encoding = "utf-8")
script
head(script)
doc     <- xmlParse(script,encoding="euc-kr")
doc <- xmlParse(script,encoding="euc-kr")
doc <- xmlParse(script,encoding="utf-8")
doc
head(doc)
Encoding(doc)
titles    <- xpathSApply(doc,'//item/title',xmlValue, encoding="utf-8")
titles
o
xml.url <- "http://rss.ohmynews.com/rss/ohmynews.xml"
script  <- getURL(xml.url, .encoding = "utf-8")
script
Encoding(script)
script <- iconv(script, from="UTF-8", to="EUC-kr")
doc <- xmlParse(script,encoding="euc-kr")
script
script  <- getURL(xml.url, .encoding = "utf-8")
script
Encoding(script)
script <- iconv(script, from="UTF-8", to="EUC-KR")
script
?iconv
script  <- getURL(xml.url, .encoding = "utf-8")
script <- iconv(script, "UTF-8","cp949")
script
script <- iconv(script, "UTF-8","UTF-8")
script  <- getURL(xml.url, .encoding = "utf-8")
script <- iconv(script, "UTF-8","UTF-8")
script
?xmlParse
?xmlParse
doc <- xmlParse(script,encoding="UTF-8")
doc
titles    <- xpathSApply(doc,'//item/title',xmlValue, encoding="euc-kr")
titles[1]
titles    <- xpathSApply(doc,'//item/title',xmlValue, encoding="UTF-8")
titles[1]
doc
xml.url <- "http://rss.ohmynews.com/rss/ohmynews.xml"
script  <- getURL(xml.url, .encoding = "utf-8")
doc <- xmlParse(script,encoding="UTF-8")
doc
titles    <- xpathSApply(doc,'//item/title',xmlValue, encoding="UTF-8")
titles[1]
titles[2]
doc
xml.url <- "http://feeds2.feedburner.com/naver_news_popular"
script  <- getURL(xml.url, .encoding = "utf-8")
script
script  <- getURL(xml.url, .encoding = "euc-kr")
script
script  <- getURL(xml.url, .encoding = "UTF-8")
script
Encoding(script)
Encoding(script) <- "UTF-8"
script
doc <- xmlParse(script,encoding="UTF-8")
doc
install.packages("twitteR")
library(twitteR)
?twitteR
market_price <- read.csv("http://dl.dropbox.com/u/8686172/marketprice.csv", fileEncoding="UTF-8")
library(parallel)
cl <- makeCluster(c("localhost","localhost"), type = "SOCK")
help(package="paralle")
help(package="paralles")
parallel
library(parallel)
help(package="parallel")
cl <- makePSOCKcluster(c("localhost","localhost"))
system.time({
a1<-ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE) )
})
library(plyr)
system.time({
a1<-ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE) )
})
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
?ddply
install.packages("foreach")
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
?registerDoSEQ
install.packages("doSNOW")
stopCluster(cl)
library(doSNOW)
registerDoSNOW(cl)
cl <- makePSOCKcluster(c("localhost","localhost"))
registerDoSNOW(cl)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
?makeCluster
cl <- makeCluster(c("localhost","localhost"), type="SOCK")
registerDoSNOW(cl)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
stopCluster(cl)
cl <- makeCluster(c("127.0.0.1","127.0.0.1"), type="SOCK")
cl <- makeCluster(c("gogamza-THINK","gogamza-THINK"), type="SOCK")
cl <- makeCluster(c("localhost","localhost"), type="SOCK")
registerDoSNOW(cl)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
a2
rm(a2)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
a2
stopCluster(cl)
stopCluster(cl)
?parallel
market_price <- read.csv("http://dl.dropbox.com/u/8686172/marketprice.csv", fileEncoding="UTF-8")
library(doSNOW)
library(foreach)
?makeCluster
cl <- makeCluster(2)
registerDoSNOW(cl)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
library(plyr)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
a2
?ddply
head(market_price)
a1<-ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE) )
a1
library(parallel)
?makeCluster
cl <- makeCluster(2)
library(foreach)
library(plyr)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
market_price <- read.csv("http://dl.dropbox.com/u/8686172/marketprice.csv", fileEncoding="UTF-8")
market_price <- read.csv("http://dl.dropbox.com/u/8686172/marketprice.csv", fileEncoding="UTF-8")
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
?foreach
doParallel
registerDoParallel(cl)
?registerDoParallel
?doParallel
help.search("doParallel")
install.packages("doParallel")
cl
registerDoParallel(cl)
library(doParallel)
registerDoParallel(cl)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
a2
rm(a2)
stopCluster(cl)
cl <- makeCluster(2)
registerDoParallel(cl)
foreach(i=1:3) %dopar% sqrt(i)
system.time({
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
})
traceback()
a2<- ddply(market_price, .(A_NAME, M_TYPE_NAME), summarize, mean_price=mean(A_PRICE),.parallel=TRUE)
a2
foreach(i=1:3) %dopar% sqrt(i)
stopCluster(cl)
stopCluster(cl)
install.packages("sqldf")
library(sqldf)
sqldf("select * from market_price limit 10;")
sqldf("select * from market_price limit 5;")
sqldf("select M_TYPE_NAME, A_NAME, avg(A_PRICE) as avg_price from market_price gropu by M_TYPE_NAME, A_NAME")
sqldf("select M_TYPE_NAME, A_NAME, avg(A_PRICE) as avg_price from market_price group by M_TYPE_NAME, A_NAME")
?sqldf
sqldf("select M_TYPE_NAME, A_NAME, avg(A_PRICE) as avg_price from market_price group by M_TYPE_NAME, A_NAME limit 10")
market_price_group_by <- sqldf("select M_TYPE_NAME, A_NAME, avg(A_PRICE) as avg_price from market_price group by M_TYPE_NAME, A_NAME")
head(market_price_group_by)
load("pew.RData")
head(raw)
melted <- melt(paw, measure.vars=c(2,3,4,5,6,7), variable.name="income", value.name="freq")
library(reshape2)
melted <- melt(paw, measure.vars=c(2,3,4,5,6,7), variable.name="income", value.name="freq")
melted <- melt(raw, measure.vars=c(2,3,4,5,6,7), variable.name="income", value.name="freq")
head(melted)
paw <- raw[,-c(8,9,10,11)]
melted <- melt(paw, measure.vars=c(2,3,4,5,6,7), variable.name="income", value.name="freq")
head(melted)
raw
head(melted)
tail(melted)
?melt
library(ggplot2)
ggplot(melted, aes(religion,freq)) + geom_bar(aes(fill="income"), position="identity")
ggplot(melted, aes(religion,freq)) + geom_bar(aes(fill="income"), stat="identity")
ggplot(melted, aes(religion,freq)) + geom_bar(aes(fill=income), stat="identity")
?geom_bar
ggplot(melted, aes(religion,freq)) + geom_bar(aes(y=..density..,fill=income), stat="identity")
ggplot(melted, aes(religion,freq)) + geom_bar(aes(fill=income), stat="identity")
library(plyr)
plyr(melted, .(religion, income), summarise, percent=freq/sum(freq))
ddply(melted, .(religion, income), summarise, percent=freq/sum(freq))
ddply(melted, .(religion), summarise, percent=freq/sum(freq))
ddply(melted, .(religion), mutate, freq_sum=sum(freq))
melted <- ddply(melted, .(religion), mutate, freq_sum=sum(freq))
melted <- ddply(melted, .(religion, income), summarise, freq_precent=freq/freq_sum)
head(melted)
ggplot(melted, aes(religion,freq)) + geom_bar(aes(fill=income), stat="identity")
ggplot(melted, aes(religion,freq_precent)) + geom_bar(aes(fill=income), stat="identity")
library(stringr)
?stringr
help(package="stringr")
str_c("Letter: ", letters)
str_c("Letter", letters, sep = ": ")
print(letters)
str_c(letters, collapse = "")
fruits <- c(
"apples and oranges and pears and bananas",
"pineapples and mangos and guavas"
)
str_split(fruits, " and ")
str_trim("  String with trailing and leading white space\t")
?theme
knit("bicdata.Rmd", encoding="UTF-8")
library(knitr)
knit("bicdata.Rmd", encoding="UTF-8")
library(sqldf)
system("pandoc -o bicdata.docx bicdata.md")
load("http://dl.dropboxusercontent.com/u/8686172/pew.RData")
load(url("http://dl.dropboxusercontent.com/u/8686172/pew.RData"))
load(url("http://dl.dropboxusercontent.com/u/8686172/pew.RData"))
head(raw)
paw <- raw[,-c(8,9,10,11)]
melted <- melt(paw, measure.vars=c(2,3,4,5,6,7), variable.name="income", value.name="freq")
library(reshape2)
melted <- melt(paw, measure.vars=c(2,3,4,5,6,7), variable.name="income", value.name="freq")
head(melted)
tail(melted)
library(ggplot2)
ggplot(melted, aes(religion,freq)) + geom_bar(aes(fill=income), stat="identity") +
theme(axis.text.x=element_text(angle=45))
melted <- ddply(melted, .(religion), mutate, freq_sum=sum(freq))
melted <- ddply(melted, .(religion), mutate, freq_sum=sum(freq))
library(plyr)
melted <- ddply(melted, .(religion), mutate, freq_sum=sum(freq))
melted <- ddply(melted, .(religion, income), summarise, freq_precent=freq/freq_sum)
head(melted)
library(knitr)
knit2wp("blog3.Rmd", title="분석하기 좋은 데이터(Tidy Data)", encoding="UTF-8")
install.packages('RWordPress', repos = 'http://www.omegahat.org/R', type = 'source')
knit2wp("blog3.Rmd", title="분석하기 좋은 데이터(Tidy Data)", encoding="UTF-8")
